{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOgF8kewlToRsLtYsQ55IkN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Сделать три сети для сегментации CityScapes"],"metadata":{"id":"8MSBTzA9bo_F"}},{"cell_type":"markdown","source":["1.Обучить на базе датасета с улицами три нейросети: линейную, U-Net (или U-Net Plus) и PSPNet   \n","\n","Сравните результаты, в выводах напишите, какая сеть оказалась точнее   \n","\n","*Для того, чтобы исследование было честным, я буду обучать НС на одинаковых данных и одинаковом кол. эпох."],"metadata":{"id":"rPMGxGsHbmR9"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"dvJghZ_VbYNa","executionInfo":{"status":"ok","timestamp":1668406573400,"user_tz":-180,"elapsed":7462,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"outputs":[],"source":["from tensorflow.keras.models import Model # Импортируем модели keras: Model\n","from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, MaxPooling2D, Conv2D, BatchNormalization, UpSampling2D # Импортируем стандартные слои keras\n","from tensorflow.keras import backend as K # Импортируем модуль backend keras'а\n","from tensorflow.keras.optimizers import Adam # Импортируем оптимизатор Adam\n","from tensorflow.keras import utils # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n","from google.colab import files # Импортируем Модуль files для работы с файлами\n","import matplotlib.pyplot as plt # Импортируем модуль pyplot библиотеки matplotlib для построения графиков\n","from tensorflow.keras.preprocessing import image # Импортируем модуль image для работы с изображениями\n","import numpy as np # Импортируем библиотеку numpy\n","from sklearn.model_selection import train_test_split\n","import time\n","import random\n","import os # Импортируем библиотеку os для раоты с фаловой системой\n","from PIL import Image # импортируем модель Image для работы с изображениями\n","\n","from google.colab import drive # Подключаем диск Google\n","\n","import matplotlib.pyplot as plt # Библиотека для рисования\n","%matplotlib inline"]},{"cell_type":"code","source":["# Подключаем свой диск Google \n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxwsCO7dgDac","executionInfo":{"status":"ok","timestamp":1668406334607,"user_tz":-180,"elapsed":16968,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}},"outputId":"d2eb73e6-9c33-46f0-8084-a29fefb65c49"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Загрузка датасета с улицами \n","!unzip /content/drive/MyDrive/Colab\\ Notebooks/Machine_learning/Datasets/cityscapes.zip -d /content/"],"metadata":{"id":"6Z0FJeJrgFfv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Исходные изображения в датасете имеют размер 512 Х 256\n","# Каждое изображение это и x и y (т.е. и вопрос и результат сегментации)\n","# Деля изображение на 2 получим изображения 256 на 256\n","# Авторы датасета сжали изображения к квадратам. Изначально они были в формате 3 Х 4.\n","# Поэтому необходимо произвести расширение\n","\n","# width_original  = 352 # ширина картинки без сжатия\n","# height_original = 256 # высота картинки без сжатия\n","\n","# 3 - 256\n","# 4 - х\n","# Вычислим новую ширину используя пропорцию\n","# x = 4*256/3 = 341,(3)\n","\n","# Предполагаем, что будем уменьшать изображение 4 раза (4 блока)\n","# Поэтому размеры изображения без сжатия необходимо 4 раза делить на 2.\n","'''\n","341,(3) / 2 / 2 / 2 / 2 = 21,(3)\n","# Округляем до 22, чтобы было чётное\n","Далее умножаем на 2 столько раз, сколько блоков задумали.\n","22 * 2 * 2 * 2 * 2 = 352 - новая ширина\n","'''\n","\n","\n","# Переводим в новый размер\n","width = 352\n","height = 256\n","\n","dataset = '/content/cityscapes/'    # Путь к датасету\n","dataset_train = dataset + \"/train\"  # Путь к обучающей выборке\n","dataset_val   = dataset + \"/val\"    # Путь к провероной выборке\n","\n","num_classes = 8 # Количество классов на изображении\n","\n","# На сколько классов сегментировали изображения авторы датасета\n","# 1  - желтый - дорожные знаки\n","# 2  - серый - здания\n","# 3  - светло-серый - столбы\n","# 4  - синий - машины\n","# 5  - бирюзовый - автобусы\n","# 6  - черный - оветительные приборы, баннеры и др.\n","# 7  - голубой - небо\n","# 8  - фиолетовый - проезжая часть\n","# 9  - розовый - пешеходные зоны\n","# 10 - темно-фиолетовый - парковки\n","# 11 - светло-фиолетовый - клумбы, тумбы и т.д.\n","# 12 - зеленый - деревья, кустарник\n","# 13 - салатовый - трава\n","# 14 - краный - люди\n","# 15 - бордовый - велосипеды\n","# 16 - оранжевый - светофоры\n","# 17 - коричневый - заборы\n","\n","# Для себя мы выберем (На сколько классов будем сегментировать):\n","# 1 - черный     - разное\n","# 2 - голубой    - небо\n","# 3 - красный    - велосипеды + люди\n","# 4 - серый      - здания + тумбы + заборы\n","# 5 - зеленый    - трава или деревья\n","# 6 - желтый     - дорожные знаки + светофоры\n","# 7 - синий      - машины + автобусы\n","# 8 - фиолетовый - проезжая часть\n","# 9 - розовый    - пешеходные зоны + парковки"],"metadata":{"id":"xkWTLy5JgLyG","executionInfo":{"status":"ok","timestamp":1668406338556,"user_tz":-180,"elapsed":320,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Функции загрузки датасета\n","\n","# Функция разделения одной картинки на две - xTrain и yTrain\n","def separate_train(name):\n","    image = Image.open(name)\n","\n","    x = image.crop((0, 0, 255, 255)).resize((width, height), Image.ANTIALIAS)\n","    y = image.crop((256, 0, 511, 255)).resize((width, height), Image.ANTIALIAS)\n","\n","    return x, y\n","\n","# Функция сегментации пикселей.\n","# Выдаёт индекс класса и цвет его сегментации для каждого полученного пикселя\n","def pixel_segmentation(pixel):\n","    index = 0\n","    color = [0, 0, 0]\n","\n","    if (110>=pixel[0]>=50) and (150>=pixel[1]>=115) and (190>=pixel[2]>=160):  # небо\n","        index = 0\n","        color = [70, 130, 180]\n","\n","    elif (157>=pixel[0]>=109) and (42>=pixel[1]>=0) and (72>=pixel[2]>=34): # велосипеды\n","        index = 1 # велосипеды + люди\n","        color = [255, 0, 0]\n","    elif (255>=pixel[0]>=185) and (50>=pixel[1]>=0) and (86>=pixel[2]>=0): # люди\n","        index = 1 # велосипеды + люди\n","        color = [255, 0, 0]\n","    \n","    elif (80>=pixel[0]>=60) and (80>=pixel[1]>=60) and (80>=pixel[2]>=60): # здания\n","        index = 2 # здания + тумбы + заборы\n","        color = [70, 70, 70]\n","    elif (115>=pixel[0]>=95) and (110>=pixel[1]>=90) and (170>=pixel[2]>=150): # тумбы\n","        index = 2 # здания + тумбы + заборы\n","        color = [70, 70, 70]\n","    elif (200>=pixel[0]>=180) and (160>=pixel[1]>=140) and (160>=pixel[2]>=140): # заборы\n","        index = 2 # здания + тумбы + заборы\n","        color = [70, 70, 70]\n","    \n","    elif (190>=pixel[0]>=120) and (255>=pixel[1]>=240) and (185>=pixel[2]>=115): # трава\n","        index = 3 # трава и деревья\n","        color = [120, 145, 20]\n","    elif (120>=pixel[0]>=60) and (160>=pixel[1]>=110) and (70>=pixel[2]>=20): # деревья\n","        index = 3 # трава и деревья\n","        color = [120, 145, 20]\n","\n","    elif (235>=pixel[0]>=160) and (230>=pixel[1]>=200) and (135>=pixel[2]>=0): # дорожные знаки\n","        index = 4 # дорожные знаки и светофоры\n","        color = [250, 250, 0]\n","    elif (255>=pixel[0]>=140) and (180>=pixel[1]>=143) and (80>=pixel[2]>=0): # светофоры\n","        index = 4 # дорожные знаки и светофоры\n","        color = [250, 250, 0]\n","\n","    elif (30>=pixel[0]>=0) and (30>=pixel[1]>=0) and (255>=pixel[2]>=125): # машины\n","        index = 5 # машины и автобусы\n","        color = [20, 20, 255]\n","    elif (30>=pixel[0]>=0) and (80>=pixel[1]>=40) and (120>=pixel[2]>=0): # автобусы\n","        index = 5 # машины и автобусы\n","        color = [20, 20, 255]\n","\n","    elif (160>=pixel[0]>=105) and (75>=pixel[1]>=55) and (150>=pixel[2]>=120): # проезжая часть\n","        index = 6 # проезжая часть\n","        color = [130, 65, 128]\n","\n","    elif (255>=pixel[0]>=210) and (70>=pixel[1]>=25) and (255>=pixel[2]>=200): # пешеходные зоны\n","        index = 7 # пешеходные зоны и парковки\n","        color = [220, 180, 200]\n","    elif (255>=pixel[0]>=240) and (180>=pixel[1]>=150) and (220>=pixel[2]>=150): # парковки\n","        index = 7 # пешеходные зоны и парковки\n","        color = [220, 180, 200]\n","\n","    return color, index\n","\n","\n","# Функция распределения изображения по классам\n","def segmentation_transform(img_obj):\n","    img_original = np.array(img_obj) # преобразовываем изображение в массив\n","    img_seg = img_original.copy() # создаем массив для нашей модели сегментации\n","    y = np.zeros((height, width, num_classes)) # создаем yTrain\n","\n","    for w in range(width):\n","        for h in range(height):\n","            img_seg[h,w], ind = pixel_segmentation(img_original[h,w])\n","            y[h,w] = utils.to_categorical(ind, num_classes)\n","\n","    return Image.fromarray(img_seg), y # Мы должны обратно из массива перевести в объект картинка"],"metadata":{"id":"VS5Xakx_iGO-","executionInfo":{"status":"ok","timestamp":1668406666371,"user_tz":-180,"elapsed":4,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Посмотрим на изображение\n","\n","x, z = separate_train(dataset_train+\"/13.jpg\") # загружаем, разделяем и выравниваем геометрию\n","y, yt = segmentation_transform(z)\n","\n","#print(x.format, x.size, x.mode)\n","#print(y.format, y.size, y.mode)\n","#print(yt.shape, yt[0:5])\n","\n","fig, axs = plt.subplots(1, 3, figsize=(20, 10)) # Создаем полотно нужной размерности\n","axs[0].imshow(x) # Отображаем самолет\n","axs[1].imshow(z) # Отображаем маску\n","axs[2].imshow(y) # Отображаем маску\n","\n","plt.show() # Показываем изображения"],"metadata":{"id":"J1_UnLWFjLVG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Формирование выборок путём преобразования изображений в NumPy массивы с сохранением в файлы.   \n","Занимает уйму времени"],"metadata":{"id":"A5HbTS7RlA1U"}},{"cell_type":"code","source":["# # Формируем обучающую выборку\n","# # Преобразует изображения в представление numpy массивов.\n","# # Которые сохраняются в файлы. При обучении НС эти файлы будут быстрее обрабатываться.\n","# xTrain = []\n","# yTrain = []\n","\n","# cur_time = time.time() # Получаем текущю метку времени\n","# flist = os.listdir(dataset_train)\n","# c = 1\n","# for filename in sorted(os.listdir(dataset_train)): # Получаем список файлов\n","#   print(c, \"из\", len(flist))\n","#   # Загружаем картинку, сразу же приводим её к нужным размерам и добавляем в массив\n","#   x, z = separate_train(dataset_train+\"/\"+filename) # получаем исходное изображение и сегментированное\n","#   _, yt = segmentation_transform(z) # сегментированное изображение переводим в OHE\n","#   xTrain.append(np.array(x))\n","#   yTrain.append(yt)\n","#   c += 1\n","\n","# xTrain = np.array(xTrain)\n","# yTrain = np.array(yTrain)\n","# finish_time = time.time()\n","# print ('Время загрузки изображений тренировочной:', finish_time - cur_time, 'c')\n","\n","# f_x = open('/content/drive/MyDrive/ITHub/ML/xTrain.npy', 'wb')\n","# f_y = open('/content/drive/MyDrive/ITHub/ML/yTrain.npy', 'wb')\n","\n","# np.save(f_x, xTrain)\n","# np.save(f_y, yTrain)"],"metadata":{"id":"64hhc02Xjlr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(xTrain.shape)\n","# print(yTrain.shape)"],"metadata":{"id":"Nen5qIHWjnhV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Формируем проверочную выборку\n","# xVal = []\n","# yVal = []\n","\n","# cur_time = time.time() # Получаем текущю метку времени\n","# flist = os.listdir(dataset_val)\n","# c = 1\n","# for filename in sorted(flist): # Получаем список файлов\n","#   print(c, \"из\", len(flist))\n","#   # Загружаем картинку, сразу же приводим её к нужным размерам и добавляем в массив\n","#   x, z = separate_train(dataset_val+\"/\"+filename) # получаем исходное изображение и сегментированное\n","#   _, yt = segmentation_transform(z) # сегментированное изображение переводим в OHE\n","#   xVal.append(np.array(x))\n","#   yVal.append(yt)\n","#   c += 1\n","\n","# xVal = np.array(xVal)\n","# yVal = np.array(yVal)\n","\n","# finish_time = time.time()\n","# print ('Время загрузки изображений проверочной выборки:', finish_time - cur_time, 'c')\n","\n","# f_x = open('/content/drive/MyDrive/ITHub/ML/xVal.npy', 'wb')\n","# f_y = open('/content/drive/MyDrive/ITHub/ML/yVal.npy', 'wb')\n","\n","# np.save(f_x, xVal)\n","# np.save(f_y, yVal)"],"metadata":{"id":"Anrb0754jnSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(xVal.shape)\n","# print(yVal.shape)"],"metadata":{"id":"AozfrKq4kyyu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Загрузка сформированных выборок-файлов NumPy\n","Сформированные выборки-файлы много весят.   \n","Их придётся подгружать с GD в виде архива  \n"],"metadata":{"id":"9uG30lF1ooJ4"}},{"cell_type":"code","source":["# Загрузка архива сформированных выборок-файлов NumPy\n","!unzip /content/drive/MyDrive/Colab\\ Notebooks/Machine_learning/Datasets/cityscapes_Val.zip -d /content/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTjNtzRcooec","executionInfo":{"status":"ok","timestamp":1668406386874,"user_tz":-180,"elapsed":17718,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}},"outputId":"462180d3-c21e-4936-b81f-7e670b53c4c0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/Colab Notebooks/Machine_learning/Datasets/cityscapes_Val.zip\n","  inflating: /content/xVal.npy       \n","  inflating: /content/yVal.npy       \n"]}]},{"cell_type":"code","source":["# Загружу валидационные данные как данные для обучения и возьму от них кусочек для валидации.\n","# Это позволит быстро обучить НС на малом числе данных\n","xTrain = np.load('/content/xVal.npy')\n","yTrain = np.load('/content/yVal.npy')\n","\n","# Разделим наши выборки на обучающую и проверочную\n","x_train, x_val, y_train, y_val = train_test_split(xTrain, yTrain, test_size = 0.1) # 0.1 => 10% на валидацию"],"metadata":{"id":"y8TJnbw-w-VJ","executionInfo":{"status":"ok","timestamp":1668406609242,"user_tz":-180,"elapsed":14126,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Функция ошибки"],"metadata":{"id":"MIVE0W5alT36"}},{"cell_type":"code","source":["def dice_coef(y_true, y_pred):\n","    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.) # Возвращаем площадь пересечения деленную на площадь объединения двух областей"],"metadata":{"id":"kjRvc7VQlPDU","executionInfo":{"status":"ok","timestamp":1668406609244,"user_tz":-180,"elapsed":12,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Функция для визуализации результата"],"metadata":{"id":"isC8aFuilowh"}},{"cell_type":"code","source":["# Функция преобразования индекса в цвет пикселя\n","def index2color(ind):\n","    index = np.argmax(ind) # Получаем индекс максимального элемента\n","    color = [0, 0, 0]\n","    if   index == 0: color = [70, 130, 180]  # небо\n","    elif index == 1: color = [255, 0, 0]     # велосипеды, люди\n","    elif index == 2: color = [70, 70, 70]    # здания + тумбы + заборы\n","    elif index == 3: color = [120, 145, 20]  # трава и деревья\n","    elif index == 4: color = [250, 250, 0]   # дорожные знаки и светофоры\n","    elif index == 5: color = [20, 20, 255]   # машины и автобусы\n","    elif index == 6: color = [130, 65, 128]  # проезжая часть\n","    elif index == 7: color = [220, 180, 200] # пешеходные зоны и парковки\n","    return color # Возвращаем цвет пикслея\n","\n","# Функция визуализации сегментированных изображений\n","def processImage(model, count, n_classes):\n","    indexes = np.random.randint(0, len(xVal), count) # Получаем count случайных индексов\n","    fig, axs = plt.subplots(3, count, figsize=(25, 5)) # Создаем полотно из n графиков\n","    for i,idx in enumerate(indexes): # Проходим по всем сгенерированным индексам\n","        predict = np.array(model.predict(xVal[idx].reshape(1, height, width, 3))) # Предиктим картику\n","        pr = predict[0] # Берем нулевой элемент из перидкта\n","        pr1 = [] # Пустой лист под сегментированную картинку из predicta\n","        pr2 = [] # Пустой лист под сегменитрованную картинку из yVal\n","        pr = pr.reshape(-1, n_classes) # Решейпим предикт\n","        yr = yVal[idx].reshape(-1, n_classes) # Решейпим yVal\n","        for k in range(len(pr)): # Проходим по всем уровням (количесвто классов)\n","            pr1.append(index2color(pr[k])) # Переводим индекс в писксель\n","            pr2.append(index2color(yr[k])) # Переводим индекс в писксель\n","            pr1 = np.array(pr1) # Преобразуем в numpy\n","            pr1 = pr1.reshape(height, width, 3) # Решейпим к размеру изображения\n","            pr2 = np.array(pr2) # Преобразуем в numpy\n","            pr2 = pr2.reshape(height, width, 3) # Решейпим к размеру изображения\n","            img = Image.fromarray(pr1.astype('uint8')) # Получаем картику из предикта\n","            axs[0,i].imshow(img.convert('RGBA')) # Отображаем на графике в первой линии\n","            axs[1,i].imshow(Image.fromarray(pr2.astype('uint8'))) # Отображаем на графике во второй линии сегментированное изображение из yVal\n","            axs[2,i].imshow(Image.fromarray(xVal[idx].astype('uint8'))) # Отображаем на графике в третьей линии оригинальное изображение        \n","    plt.show()"],"metadata":{"id":"Jn_1ZaQlln8_","executionInfo":{"status":"ok","timestamp":1668406611616,"user_tz":-180,"elapsed":316,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Линейная модель НС для Сегментации"],"metadata":{"id":"kJ0bwmm9l-_4"}},{"cell_type":"code","source":["def linearSegmentationNet(num_classes, input_shape):\n","    img_input = Input(input_shape)                                          # Создаем входной слой с размерностью input_shape\n","    x = Conv2D(128, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                             # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                               # Добавляем слой Activation\n","\n","    x = Conv2D(128, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 128-нейронами\n","    x = BatchNormalization()(x)                                             # Добавляем слой BatchNormalization\n","    x = Activation('relu')(x)                                               # Добавляем слой Activation\n","\n","    x = Conv2D(num_classes,(3, 3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","    model = Model(img_input, x)                                             # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","    # Компилируем модель\n","    model.compile(optimizer=Adam(learning_rate=1e-3),\n","                    loss='categorical_crossentropy',\n","                    metrics=[dice_coef])\n","    return model # Возвращаем сформированную модель"],"metadata":{"id":"J3Vo-DF5lwWv","executionInfo":{"status":"ok","timestamp":1668406390766,"user_tz":-180,"elapsed":5,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Создаем модель\n","modelL = linearSegmentationNet(num_classes, (height, width, 3)) # Создаем линейную моель\n","modelL.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ucrQIh3mINH","executionInfo":{"status":"ok","timestamp":1668406396295,"user_tz":-180,"elapsed":2824,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}},"outputId":"5c1f5fb4-b686-412e-99ad-72743bc7e797"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 256, 352, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 256, 352, 128)     3584      \n","                                                                 \n"," batch_normalization (BatchN  (None, 256, 352, 128)    512       \n"," ormalization)                                                   \n","                                                                 \n"," activation (Activation)     (None, 256, 352, 128)     0         \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 256, 352, 128)     147584    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 256, 352, 128)    512       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_1 (Activation)   (None, 256, 352, 128)     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 256, 352, 8)       9224      \n","                                                                 \n","=================================================================\n","Total params: 161,416\n","Trainable params: 160,904\n","Non-trainable params: 512\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Обучаем модель \n","# x_train, x_val, y_train, y_val \n","history = modelL.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val)) "],"metadata":{"id":"OfpHnk5umJqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Отобразим график обучения модели\n","plt.plot(history.history['dice_coef'])\n","plt.plot(history.history['val_dice_coef'])\n","plt.show()"],"metadata":{"id":"pKqt4QfkmKn4","executionInfo":{"status":"aborted","timestamp":1668406436965,"user_tz":-180,"elapsed":8,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["processImage(modelL, 5, num_classes)\n","# TODO: Почему этот блок выполнился с ошибкой?"],"metadata":{"id":"xkTthl0-mL1u","executionInfo":{"status":"aborted","timestamp":1668406436966,"user_tz":-180,"elapsed":9,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Unet модель НС для Сегментации"],"metadata":{"id":"9bJaQ9w3mQvH"}},{"cell_type":"code","source":["# Unet делать не обязательно, если сделал Unet Plus\n","\n","def unet(num_classes, input_shape):\n","  img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n","\n","  # Block 1\n","  x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n","\n","  x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n","\n","  # Block 2\n","  x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)        # Добавляем Conv2D-слой с 128-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n","\n","  x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n","\n","  # Block 3\n","  x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  block_3_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_3_out\n","\n","  x = MaxPooling2D()(block_3_out)                                        # Добавляем слой MaxPooling2D\n","\n","  # Block 4\n","  x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)        # Добавляем Conv2D-слой с 512-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  block_4_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_4_out\n","  \n","  x = block_4_out \n","\n","  # UP 2\n","  x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 256 нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = concatenate([x, block_3_out])                                      # Объединем текущий слой со слоем block_3_out\n","  x = Conv2D(256, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 256 нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(256, (3, 3), padding='same')(x)\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  # UP 3\n","  x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 128 нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = concatenate([x, block_2_out])                                      # Объединем текущий слой со слоем block_2_out\n","  x = Conv2D(128, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 128 нейронами\n","  x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x)                                              # Добавляем слой Activation\n","\n","  x = Conv2D(128, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 128 нейронами\n","  x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x) # Добавляем слой Activation\n","\n","  # UP 4\n","  x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n","  x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x) # Добавляем слой Activation\n","\n","  x = concatenate([x, block_1_out])  # Объединем текущий слой со слоем block_1_out\n","  x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","  x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x) # Добавляем слой Activation\n","\n","  x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n","  x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n","  x = Activation('relu')(x) # Добавляем слой Activation\n","\n","  x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n","\n","  model = Model(img_input, x) # Создаем модель с входом 'img_input' и выходом 'x'\n","\n","  # Компилируем модель \n","  model.compile(optimizer=Adam(),\n","                loss='categorical_crossentropy',\n","                metrics=[dice_coef])\n","    \n","  return model # Возвращаем сформированную модель"],"metadata":{"id":"mltNRZrCmfna","executionInfo":{"status":"ok","timestamp":1668406694057,"user_tz":-180,"elapsed":387,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Создаем модель\n","modelUnet = unet(num_classes, (height, width, 3))\n","modelUnet.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"8DMmCZ8GvKDn","executionInfo":{"status":"error","timestamp":1668406696898,"user_tz":-180,"elapsed":327,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}},"outputId":"02292572-b71c-4cbc-b52f-869bd2a4809e"},"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-ee3eaec24d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Создаем модель\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelUnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodelUnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"]}]},{"cell_type":"code","source":["history = modelUnet.fit(x_train, y_train, epochs=10, batch_size=16, validation_data = (x_val, y_val)) # Обучаем модель на выборке по трем классам\n"],"metadata":{"id":"MqUX-X4qxeYR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Unet Plus модель НС для Сегментации"],"metadata":{"id":"DnCRrGeQmZk8"}},{"cell_type":"code","source":["# Unet Plus делать не обязательно, если сделал Unet\n","\n"],"metadata":{"id":"lBPSXuAmmf6L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PSPNet модель НС для Сегментации"],"metadata":{"id":"lVitBoIVmZty"}},{"cell_type":"code","source":["# \n","\n"],"metadata":{"id":"gycRAMiymgm_","executionInfo":{"status":"ok","timestamp":1668405395078,"user_tz":-180,"elapsed":8,"user":{"displayName":"Глеб Колонин","userId":"16800121630135430864"}}},"execution_count":1,"outputs":[]}]}